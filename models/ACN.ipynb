{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as tf\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os,sys\n",
    "root_dir='/mnt/e/Programming_Projects/CLDV_PRACTICAL/CVDL_Practical'\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from data.CK_plus import CK_plus\n",
    "from data.FER2013 import FER2013\n",
    "from data.utils.augmentations import randomErasing_flip_rotate_transforms\n",
    "from models.utils.discriminativ_loss import AffinityLoss\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class getcfg():\n",
    "    def __init__(self):\n",
    "        self.probability=0.8\n",
    "        self.min_area=0.02\n",
    "        self.max_area=0.10\n",
    "        self.min_aspect_ratio=0.3\n",
    "        self.max_aspect_ratio=3.0\n",
    "        self.rotation_angle=25\n",
    "\n",
    "cfg=getcfg()\n",
    "cfg.rotation_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform, test_transform = randomErasing_flip_rotate_transforms(cfg)['train'], randomErasing_flip_rotate_transforms(cfg)['test']\n",
    "\n",
    "train_data = CK_plus(transform=train_transform,split='train')\n",
    "test_data = CK_plus(transform=test_transform,split='test')\n",
    "\n",
    "# # use fer\n",
    "# train_data = FER2013(transform=train_transform,split='train')\n",
    "# test_data = FER2013(transform=test_transform,split='test')\n",
    "\n",
    "train_data_loader = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "test_data_loader = DataLoader(test_data,batch_size=32,shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====testing the attention block=====\n",
      "ATT input shape: torch.Size([32, 16, 16])\n",
      "input shape: torch.Size([32, 16, 16]),value shape: torch.Size([32, 16, 1, 16, 16])\n",
      "alignment shape after softmax: torch.Size([32, 16, 16]),transofrmed origin torch.Size([32, 16, 256])\n",
      "after matmul: torch.Size([32, 16, 256])\n",
      "after reshape: torch.Size([32, 16, 1, 16, 16])\n",
      "output shape: torch.Size([32, 16, 1, 16, 16])\n",
      "ATT output shape: torch.Size([32, 16, 1, 16, 16])\n",
      "=====testing the window init layer=====\n",
      "input shape!!: torch.Size([32, 1, 64, 64])\n",
      "output shape: torch.Size([32, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# definition of Attention feature map\n",
    "\n",
    "#defining the attention block\n",
    "class alighnment_score(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(alighnment_score,self).__init__()\n",
    "        self.in_channels=in_channels\n",
    "        self.out_channels=out_channels\n",
    "        # self.fc_up = nn.Linear(in_channels,2*out_channels)\n",
    "        # self.fc_down = nn.Linear(2*out_channels,out_channels)\n",
    "        self.layernorm_in = nn.LayerNorm(in_channels)\n",
    "        self.layernorm_out = nn.LayerNorm(out_channels)\n",
    "        self.Q=nn.Linear(in_channels,out_channels)\n",
    "        self.K=nn.Linear(in_channels,out_channels)\n",
    "    def forward(self,x,value): # (b,16,8) (b,16,1,16,16)\n",
    "        #print(f\"input shape: {x.shape},value shape: {value.shape}\")\n",
    "        origin=value\n",
    "        x=self.layernorm_in(x)\n",
    "        Q=self.Q(x)\n",
    "        K=self.K(x)\n",
    "        alignment=torch.matmul(Q,K.transpose(-2,-1))/np.sqrt(self.out_channels)\n",
    "        alighnment_score=F.softmax(alignment,dim=-1) #(b,16,16)\n",
    "        #print(f\"alignment shape after softmax: {alighnment_score.shape},transofrmed origin {value.squeeze(2).view(value.size(0),value.size(1),-1).shape}\")\n",
    "        \n",
    "        # (b,16,16) (b,16,16,16)\n",
    "        att=torch.matmul(alighnment_score,value.squeeze(2).view(value.size(0),value.size(1),-1))\n",
    "        #print(f\"after matmul: {att.shape}\")\n",
    "        \n",
    "        #reshape the output\n",
    "        att=att.view(value.size(0),value.size(1),1,value.size(3),value.size(4))\n",
    "        \n",
    "        att=att+origin\n",
    "        #print(f\"after reshape: {att.shape}\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        att=self.layernorm_out(att)\n",
    "        \n",
    "        #print(f\"output shape: {att.shape}\")\n",
    "        return att\n",
    "    \n",
    "# testing the attention block\n",
    "b=32\n",
    "c=4*4\n",
    "p=16\n",
    "x=torch.randn(b,c,p)\n",
    "value=torch.randn(b,c,1,p,p)\n",
    "print(f\"=====testing the attention block=====\")\n",
    "print(f\"ATT input shape: {x.shape}\")\n",
    "attention=alighnment_score(in_channels=4*4,out_channels=16)\n",
    "output=attention(x,value)\n",
    "print(f\"ATT output shape: {output.shape}\")\n",
    "\n",
    "# definine the convolution init layer\n",
    "class window_init(nn.Module):\n",
    "    def __init__(self,patch_size,dmodel):\n",
    "        super(window_init,self).__init__()\n",
    "        kernelsize=patch_size/dmodel**0.5\n",
    "        assert kernelsize==int(kernelsize), f\"patch size {patch_size} is not divisible by dmodel {dmodel**0,5}\"\n",
    "        kernelsize=int(kernelsize)\n",
    "        self.conv=nn.Conv2d(1,1,kernel_size=kernelsize,stride=kernelsize)\n",
    "        self.relu=nn.ReLU()\n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        x=self.relu(x)\n",
    "        return x\n",
    "\n",
    "# testing the window init layer\n",
    "b=32\n",
    "c=1\n",
    "h=64\n",
    "w=64\n",
    "\n",
    "x=torch.randn(b,c,h,w)\n",
    "print(f\"=====testing the window init layer=====\")\n",
    "print(f\"input shape!!: {x.shape}\")\n",
    "window=window_init(16,64)\n",
    "output=window(x)\n",
    "print(f\"output shape: {output.shape}\")\n",
    "\n",
    "# using torchvison resnet for after attention block\n",
    "from torchvision.models import resnet18\n",
    "class after_attention(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(after_attention,self).__init__()\n",
    "        self.in_channels=in_channels\n",
    "        self.out_channels=out_channels\n",
    "        self.resnet=resnet18(pretrained=False)\n",
    "        self.resnet.fc=nn.Linear(512,out_channels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        feature=x.view(x.size(0),-1)\n",
    "        x=self.resnet(x.repeat(1,3,1,1))\n",
    "        return feature,x\n",
    "    \n",
    "\n",
    "# define image split layer\n",
    "class image_split(nn.Module):\n",
    "    \"\"\"\n",
    "    Splits an image into patches of size (patch_size x patch_size).\n",
    "    Input shape:  (B, C, H, W)\n",
    "    Output shape: (B, N, C, patch_size, patch_size), where N = (H // patch_size) * (W // patch_size)\n",
    "    \"\"\"\n",
    "    def __init__(self, patch_size: int):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: Input tensor of shape [B, C, H, W]\n",
    "        \"\"\"\n",
    "        b, c, h, w = x.size()\n",
    "        patch_size = self.patch_size\n",
    "        \n",
    "        num_patches = (h // patch_size) * (w // patch_size)\n",
    "        vertical_patches = h // patch_size\n",
    "        horizontal_patches = w // patch_size\n",
    "        \n",
    "        # Split the image into patches\n",
    "        x = x.unfold(2, patch_size, patch_size).unfold(3, patch_size, patch_size)\n",
    "        x = x.contiguous().view(b, c, num_patches, patch_size, patch_size)\n",
    "        x = x.permute(0, 2, 1, 3, 4).contiguous()\n",
    "        \n",
    "        return x\n",
    "    \n",
    "#define the image reconstruction layer\n",
    "class image_reconstruction(nn.Module):\n",
    "    \"\"\"\n",
    "    Reconstructs the original image from patches.\n",
    "    Input shape:  (B, N, C, patch_size, patch_size), where N = (H // patch_size) * (W // patch_size)\n",
    "    Output shape: (B, C, H, W)\n",
    "    \"\"\"\n",
    "    def __init__(self, patch_size: int):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def forward(self, x: torch.Tensor, original_hw: tuple):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape [B, N, C, patch_size, patch_size]\n",
    "        original_hw: Tuple (H, W) - original image dimensions\n",
    "        \"\"\"\n",
    "        b, n, c, patch_size, _ = x.size()\n",
    "        h, w = original_hw\n",
    "        \n",
    "        assert patch_size == self.patch_size, \"Patch size mismatch during reconstruction\"\n",
    "        \n",
    "        # Compute the number of patches along each dimension\n",
    "        patches_h = h // patch_size\n",
    "        patches_w = w // patch_size\n",
    "\n",
    "        # Ensure the number of patches matches\n",
    "        assert n == patches_h * patches_w, \\\n",
    "            f\"Number of patches ({n}) does not match expected ({patches_h * patches_w})\"\n",
    "\n",
    "        # Reshape and permute to reconstruct the image\n",
    "        x = x.view(b, patches_h, patches_w, c, patch_size, patch_size)\n",
    "        x = x.permute(0, 3, 1, 4, 2, 5).contiguous()\n",
    "        x = x.view(b, c, h, w)\n",
    "\n",
    "        return x\n",
    "\n",
    "# defining the Attention feature cluster network\n",
    "class AttentionFeatureCluster(nn.Module):\n",
    "    def __init__(self,patch_size,feature_size,dmodel,num_classes):\n",
    "        super(AttentionFeatureCluster,self).__init__()\n",
    "        self.patch_size=patch_size\n",
    "        self.feature_size=feature_size\n",
    "        self.num_classes=num_classes\n",
    "        self.num_patches=(self.feature_size//self.patch_size)**2\n",
    "        self.window_init=window_init(self.patch_size,dmodel)\n",
    "        self.attention=alighnment_score((8)**2, self.patch_size)\n",
    "        \n",
    "        self.after_attention=after_attention(self.feature_size**2,self.num_classes)\n",
    "        \n",
    "        self.att_image_split=image_split(8)\n",
    "        self.image_split=image_split(self.patch_size)\n",
    "        self.image_reconstruction=image_reconstruction(self.patch_size)\n",
    "        \n",
    "        self.dropout=nn.Dropout(0.5)\n",
    "    def forward(self,x):\n",
    "        b,c,h,w=x.size() # (b,1,64,64)\n",
    "        value=self.image_split(x) # (b,16,16,16)\n",
    "        #print(f\"value shape after split: {value.shape}\")\n",
    "        \n",
    "        \n",
    "        x=self.window_init(x) # (b,1,4,4)\n",
    "        x=self.dropout(x)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x=self.att_image_split(x) # (b,16,16,16)\n",
    "        #print(f\"shape after split: {x.shape}\")\n",
    "        \n",
    "\n",
    "        x=x.view(b,self.num_patches,-1) # (b,16,16)\n",
    "        \n",
    "        # apply the attention block\n",
    "        x=self.attention(x,value)\n",
    "        #print(f\"shape after attention: {x.shape}\") # (b,number_of_patches,1,16,16)\n",
    "        # fig,ax=plt.subplots(1,5,figsize=(20,5))\n",
    "        # ax[0].imshow(x[0,0,0].cpu().detach().numpy())\n",
    "        # ax[1].imshow(x[0,1,0].cpu().detach().numpy())\n",
    "        # ax[2].imshow(x[0,2,0].cpu().detach().numpy())\n",
    "        # ax[3].imshow(x[0,3,0].cpu().detach().numpy())\n",
    "        \n",
    "        # reconstruct the image\n",
    "        x=self.image_reconstruction(x,(64,64))\n",
    "        plt.imshow(x[0,0].cpu().detach().numpy())\n",
    "        #print(f\"shape after reconstruction: {x.shape}\")\n",
    "        x=self.dropout(x)\n",
    "        \n",
    "        \n",
    "        # apply the fc layer\n",
    "        feature,x=self.after_attention(x)\n",
    "        return feature,x\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: torch.Size([32, 1, 64, 64])\n",
      "shape after split: torch.Size([32, 16, 1, 16, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f480c118230>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ImageSplit(nn.Module):\n",
    "    \"\"\"\n",
    "    Splits an image into patches of size (patch_size x patch_size).\n",
    "    Input shape:  (B, C, H, W)\n",
    "    Output shape: (B, N, C, patch_size, patch_size), where N = (H // patch_size) * (W // patch_size)\n",
    "    \"\"\"\n",
    "    def __init__(self, patch_size: int):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        x: Input tensor of shape [B, C, H, W]\n",
    "        \"\"\"\n",
    "        b, c, h, w = x.size()\n",
    "        patch_size = self.patch_size\n",
    "        \n",
    "        num_patches = (h // patch_size) * (w // patch_size)\n",
    "        vertical_patches = h // patch_size\n",
    "        horizontal_patches = w // patch_size\n",
    "        \n",
    "        # Split the image into patches\n",
    "        x = x.unfold(2, patch_size, patch_size).unfold(3, patch_size, patch_size)\n",
    "        x = x.contiguous().view(b, c, num_patches, patch_size, patch_size)\n",
    "        x = x.permute(0, 2, 1, 3, 4).contiguous()\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class ImageReconstruction(nn.Module):\n",
    "    \"\"\"\n",
    "    Reconstructs the original image from patches.\n",
    "    Input shape:  (B, N, C, patch_size, patch_size), where N = (H // patch_size) * (W // patch_size)\n",
    "    Output shape: (B, C, H, W)\n",
    "    \"\"\"\n",
    "    def __init__(self, patch_size: int):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def forward(self, x: torch.Tensor, original_hw: tuple):\n",
    "        \"\"\"\n",
    "        x: Tensor of shape [B, N, C, patch_size, patch_size]\n",
    "        original_hw: Tuple (H, W) - original image dimensions\n",
    "        \"\"\"\n",
    "        b, n, c, patch_size, _ = x.size()\n",
    "        h, w = original_hw\n",
    "        \n",
    "        assert patch_size == self.patch_size, \"Patch size mismatch during reconstruction\"\n",
    "        \n",
    "        # Compute the number of patches along each dimension\n",
    "        patches_h = h // patch_size\n",
    "        patches_w = w // patch_size\n",
    "\n",
    "        # Ensure the number of patches matches\n",
    "        assert n == patches_h * patches_w, \\\n",
    "            f\"Number of patches ({n}) does not match expected ({patches_h * patches_w})\"\n",
    "\n",
    "        # Reshape and permute to reconstruct the image\n",
    "        x = x.view(b, patches_h, patches_w, c, patch_size, patch_size)\n",
    "        x = x.permute(0, 3, 1, 4, 2, 5).contiguous()\n",
    "        x = x.view(b, c, h, w)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# test image split and image reconstruction\n",
    "img=next(iter(train_data_loader))[0]\n",
    "print(f\"image shape: {img.shape}\")\n",
    "plt.imshow(img[0,0].detach().cpu().numpy())\n",
    "image_split_layer=ImageSplit(16)\n",
    "image_reconstruction_layer=ImageReconstruction(16)\n",
    "patches=image_split_layer(img)\n",
    "print(f\"shape after split: {patches.shape}\")\n",
    "reconstructed_img=image_reconstruction_layer(patches,(64,64))\n",
    "plt.imshow(reconstructed_img[0,0].detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/rapids-21.12/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/rapids-21.12/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img=next(iter(train_data_loader))[0]\n",
    "#plt.imshow(img[0,0].detach().cpu().numpy())\n",
    "img=img.to('cuda')\n",
    "print(img.shape)\n",
    "attention_cluster=AttentionFeatureCluster(8,64,64,6)\n",
    "attention_cluster=attention_cluster.to('cuda')\n",
    "attention_cluster(img)[1].shape\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_325866/3903676500.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for data in tqdm(train_data_loader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bef6935280843db897962197c4e43a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/rapids-21.12/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_325866/3903676500.py:35: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for data in tqdm(test_data_loader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6efcc0dde54f4fd5a3f8e9723fabc3ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "train_loss: 1.6014, train_acc: 0.3694\n",
      "test_loss: 82.5690, test_acc: 0.3571\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_loss=AffinityLoss(64*64,6)\n",
    "feature_loss=feature_loss.to('cuda')\n",
    "predic_loss=nn.CrossEntropyLoss()\n",
    "predic_loss=predic_loss.to('cuda')\n",
    "\n",
    "optimizer=optim.Adam(attention_cluster.parameters(),lr=0.001)\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def train(model,train_data_loader,optimizer,feature_loss,predic_loss):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    for data in tqdm(train_data_loader):\n",
    "        model.zero_grad()\n",
    "        img,label=data\n",
    "        img=img.to('cuda')\n",
    "        label=label.to('cuda')\n",
    "        feature,predic=model(img)\n",
    "        loss1=0.1*feature_loss(feature,label)\n",
    "        loss2=predic_loss(predic,label)\n",
    "        loss=loss2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss.item()\n",
    "        total_correct+=predic.argmax(dim=1).eq(label.argmax(dim=1)).sum().item()\n",
    "    return total_loss/len(train_data_loader),total_correct/len(train_data_loader.dataset)\n",
    "\n",
    "def test(model,test_data_loader,feature_loss,predic_loss):\n",
    "    model.eval()\n",
    "    total_loss=0\n",
    "    total_correct=0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(test_data_loader):\n",
    "            img,label=data\n",
    "            img=img.to('cuda')\n",
    "            label=label.to('cuda')\n",
    "            feature,predic=model(img)\n",
    "            loss1=feature_loss(feature,label)\n",
    "            loss2=predic_loss(predic,label)\n",
    "            loss=loss1+loss2\n",
    "            total_loss+=loss.item()\n",
    "            total_correct+=predic.argmax(dim=1).eq(label.argmax(dim=1)).sum().item()\n",
    "    return total_loss/len(test_data_loader),total_correct/len(test_data_loader.dataset)\n",
    "\n",
    "train_loss,train_acc=train(attention_cluster,train_data_loader,optimizer,feature_loss,predic_loss)\n",
    "test_loss,test_acc=test(attention_cluster,test_data_loader,feature_loss,predic_loss)\n",
    "print(f\"train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}\")\n",
    "print(f\"test_loss: {test_loss:.4f}, test_acc: {test_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_325866/774573625.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm(range(num_epochs)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129b63824341434eb621864872bc440b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/70 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_325866/3903676500.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for data in tqdm(train_data_loader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b711973d204f2b9fb8ba071665c896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_325866/3903676500.py:35: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for data in tqdm(test_data_loader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc70fe6ba68474eb1129a2a88ebd243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 1/70\n",
      "train_loss: 1.2517, train_acc: 0.5363\n",
      "test_loss: 84.1938, test_acc: 0.5051\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b24e292538a4d0098573ea1be3939af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1801d34ce3e94ca6bab7b0669be054ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 2/70\n",
      "train_loss: 1.1033, train_acc: 0.5936\n",
      "test_loss: 87.3564, test_acc: 0.5204\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f558aecd3b1044a28abfbdbe969ba43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c306d50fbec4465fb8d3c1fc5ef0ec0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 3/70\n",
      "train_loss: 0.9738, train_acc: 0.6446\n",
      "test_loss: 79.0959, test_acc: 0.5663\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b82b131dfa274e859205a29bd8885e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cfdf90019446598300f0e2487b3896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 4/70\n",
      "train_loss: 0.9269, train_acc: 0.6548\n",
      "test_loss: 86.0860, test_acc: 0.5816\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c46bdf20304acdbf2bb25138ba2d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dabb868f6d45e6b59b5bb1f7f14779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 5/70\n",
      "train_loss: 0.8423, train_acc: 0.6904\n",
      "test_loss: 81.4017, test_acc: 0.6939\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cb6e816c0e400bb64ae18f0957bc52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523b5fef0c78481286b659e81e373ccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 6/70\n",
      "train_loss: 0.8426, train_acc: 0.6854\n",
      "test_loss: 92.5189, test_acc: 0.5153\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af91150925be418790f5cddfb3d26d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f460134c6d94612aff521fc29ab3a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 7/70\n",
      "train_loss: 0.7665, train_acc: 0.7096\n",
      "test_loss: 89.7868, test_acc: 0.6735\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e91e2760c5343068ea8c19fa6f20174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ea42c3b31d4fcc94af98cbf49d0fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 8/70\n",
      "train_loss: 0.7216, train_acc: 0.7376\n",
      "test_loss: 75.4405, test_acc: 0.7143\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf41a54327d5420bb0f8b1255e4ee6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c3af8f43934dc4a22d34764f29a195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 9/70\n",
      "train_loss: 0.7145, train_acc: 0.7427\n",
      "test_loss: 90.2480, test_acc: 0.5612\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3deafbb9bfc4d83bc4ffa954a263566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c7b2d4f4e7491888a85f40948ba630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 10/70\n",
      "train_loss: 0.6762, train_acc: 0.7554\n",
      "test_loss: 82.1615, test_acc: 0.7092\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aededd3c03c4fc4994b8ef22e44f315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d106c054fe4311bd4b5ff8a87e7c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 11/70\n",
      "train_loss: 0.6259, train_acc: 0.7783\n",
      "test_loss: 91.1446, test_acc: 0.6888\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264dad5207c1455e90bf29045bfd806b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2128b667a4e9437a961aa86930af5ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 12/70\n",
      "train_loss: 0.6040, train_acc: 0.7682\n",
      "test_loss: 95.8858, test_acc: 0.7449\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c53660673d4a5a89fa002e24d0bd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d692badeadd44b8b392ef413679e543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 13/70\n",
      "train_loss: 0.6363, train_acc: 0.7682\n",
      "test_loss: 91.1950, test_acc: 0.7500\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b655eead954c2b986e27ede326c274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d298bd9df64f89945e7d813ad2a70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 14/70\n",
      "train_loss: 0.5690, train_acc: 0.7936\n",
      "test_loss: 92.4535, test_acc: 0.7653\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9d85008a744a1186d68f30fd7c36fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1e502f029946e883e10a344cb7a0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 15/70\n",
      "train_loss: 0.5653, train_acc: 0.7898\n",
      "test_loss: 84.2823, test_acc: 0.7602\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2fbcd659184c0781c9c16939be008a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2db0310bff545faaccf7702ba26e11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 16/70\n",
      "train_loss: 0.5925, train_acc: 0.7898\n",
      "test_loss: 96.8242, test_acc: 0.7704\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4b033b0a724ee3b60f847dbba8a3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e24beb52b3423ea8e555ce7f98f30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 17/70\n",
      "train_loss: 0.5044, train_acc: 0.8013\n",
      "test_loss: 87.4860, test_acc: 0.7398\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40106e5761ac45db85d2afdd45c77729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4ad87df124345d6b7dd21afd353f267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 18/70\n",
      "train_loss: 0.5045, train_acc: 0.8242\n",
      "test_loss: 83.3237, test_acc: 0.8520\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6586994962b14e4bacc3bc15a134bbcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c918277a0d2e41cb9cb5c729b85933bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 19/70\n",
      "train_loss: 0.4995, train_acc: 0.8229\n",
      "test_loss: 82.9930, test_acc: 0.8163\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda277dc841c40fc897d0d9808b6280d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd5d0cc4e76d4352a3735a07c6d8b411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 20/70\n",
      "train_loss: 0.5243, train_acc: 0.8166\n",
      "test_loss: 86.2653, test_acc: 0.7551\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ed8c72749b448a9fa568979fbcc9c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0d6cf05226482ab996477f4f59a01c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 21/70\n",
      "train_loss: 0.4521, train_acc: 0.8573\n",
      "test_loss: 81.4101, test_acc: 0.8418\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4056ff99c9704449af200a7fcd5c98a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bf599082af4b8296973f26e220b247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 22/70\n",
      "train_loss: 0.4828, train_acc: 0.8382\n",
      "test_loss: 81.4533, test_acc: 0.8112\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6922ed44271b4deda5740286198f3db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eee78dd64b745889048e2b3c8cd96db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 23/70\n",
      "train_loss: 0.5182, train_acc: 0.8318\n",
      "test_loss: 72.4632, test_acc: 0.7857\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041dac67529848bb9013e44ab46cc43d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d271a97c3f4e4da91e9ecc22f8366d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 24/70\n",
      "train_loss: 0.4461, train_acc: 0.8344\n",
      "test_loss: 82.4802, test_acc: 0.8367\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10937af704634a6293110650d19df571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c298f7c2ad243028b3d4c581057f9cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 25/70\n",
      "train_loss: 0.4135, train_acc: 0.8573\n",
      "test_loss: 83.3290, test_acc: 0.8367\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33089a1286447de816b1494b981de4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93da97310b49471da731d41a05d0c7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 26/70\n",
      "train_loss: 0.4171, train_acc: 0.8586\n",
      "test_loss: 89.6154, test_acc: 0.7959\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a331d8d1934a518388ecb9924e52bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8eff4c9c4b4e4bb69335cb7a7349ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 27/70\n",
      "train_loss: 0.4597, train_acc: 0.8268\n",
      "test_loss: 93.9211, test_acc: 0.8010\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b46be7461d7a4dd3bd5b73b520337f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882971eff9d547728c8af1a90d3786fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 28/70\n",
      "train_loss: 0.4480, train_acc: 0.8395\n",
      "test_loss: 85.2362, test_acc: 0.8316\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4602ccf7254a4d67a1d294bcf1de0c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9bb10265cd49d09dd2b2decbfd9f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 29/70\n",
      "train_loss: 0.3868, train_acc: 0.8726\n",
      "test_loss: 88.8566, test_acc: 0.8010\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecb08ae0a284eb4acc6a5994b4c22c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069d9e7a824243fe847ed255b0c73312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 30/70\n",
      "train_loss: 0.3663, train_acc: 0.8803\n",
      "test_loss: 81.2691, test_acc: 0.8418\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b999c353a4408da57bc52db29ff7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9439c471971f4211b2ccb5883426ba2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 31/70\n",
      "train_loss: 0.4170, train_acc: 0.8535\n",
      "test_loss: 86.6321, test_acc: 0.8163\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05990689caed4cb8bc18af9100f99f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978d67e064924058a2f143f0f526579c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 32/70\n",
      "train_loss: 0.4036, train_acc: 0.8535\n",
      "test_loss: 89.3199, test_acc: 0.8367\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b24919f2fe4424bb73b6dd89cc95d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2080709806248f29f57391740613984",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 33/70\n",
      "train_loss: 0.4353, train_acc: 0.8561\n",
      "test_loss: 82.3615, test_acc: 0.8724\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad30fc5adc7472691af7e6f25064aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386bc46bed6146a781c5c584a094ee94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 34/70\n",
      "train_loss: 0.3555, train_acc: 0.8764\n",
      "test_loss: 89.8884, test_acc: 0.8265\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e99f56595d945e29858df94dd59fe41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a149deffd30458c9fce49b019d0476f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 35/70\n",
      "train_loss: 0.3517, train_acc: 0.8790\n",
      "test_loss: 89.6411, test_acc: 0.8571\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c689b5629d14c88bf8c8deb64c707a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c788dfd5a5ba4a30801ffda69cda57a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 36/70\n",
      "train_loss: 0.3753, train_acc: 0.8522\n",
      "test_loss: 79.5108, test_acc: 0.8469\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a52f654b5f04d9a9e747a6cc70f44e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ea2f9c45624298956ed62e0444daa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 37/70\n",
      "train_loss: 0.3407, train_acc: 0.8803\n",
      "test_loss: 85.5454, test_acc: 0.8673\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c40c3585ad4f27b3adf26cc5785ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6811db2a50f454385abb34df7aad32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 38/70\n",
      "train_loss: 0.3374, train_acc: 0.8854\n",
      "test_loss: 80.3629, test_acc: 0.8418\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa0980fe08e436e9cfc7b120ceda603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b662946aa23048b48f6dce9f58e45dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 39/70\n",
      "train_loss: 0.3667, train_acc: 0.8790\n",
      "test_loss: 89.7546, test_acc: 0.7143\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4b68ef1da243adac2c7d4307e896a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67376bd2dbca4ceabb43f9c7636148a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 40/70\n",
      "train_loss: 0.3384, train_acc: 0.8713\n",
      "test_loss: 84.5016, test_acc: 0.8265\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36fbc759a6a479f9d43e42bfd686623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d982598edb3409cb4381a8ddbd4164f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 41/70\n",
      "train_loss: 0.3375, train_acc: 0.8752\n",
      "test_loss: 86.6866, test_acc: 0.8010\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e2537a18fa46d08eae19055ec97a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ade25ab9c64e0fb707febfc4977459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 42/70\n",
      "train_loss: 0.3180, train_acc: 0.8828\n",
      "test_loss: 77.4008, test_acc: 0.9031\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0657e8fbe6be41aa8cf6f94961ec031e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e642657f36a443228ae2d350251ef46a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 43/70\n",
      "train_loss: 0.3314, train_acc: 0.8866\n",
      "test_loss: 85.5154, test_acc: 0.8061\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74d4e5bfbe14394ab7c21ac3a568a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b805108e9b5e4fb78fd06f41edc534d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 44/70\n",
      "train_loss: 0.2932, train_acc: 0.9057\n",
      "test_loss: 79.6224, test_acc: 0.8724\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f26ff4b19c40fe9acebd361cdbd6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf5ed87bef945de8739852fe64a2b04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 45/70\n",
      "train_loss: 0.2933, train_acc: 0.8981\n",
      "test_loss: 84.9287, test_acc: 0.8316\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e139ce4ffc341b299ed6d30a6eaca2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1036da28b26f4e96a90753bb00eb8ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 46/70\n",
      "train_loss: 0.3149, train_acc: 0.8930\n",
      "test_loss: 87.7145, test_acc: 0.8520\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "225d19891c794c729740207933098440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7232aa3467ae4f97a1a10fc948eda801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 47/70\n",
      "train_loss: 0.3022, train_acc: 0.9070\n",
      "test_loss: 87.0085, test_acc: 0.8469\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3e316240454753a0ab29efa480056a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f67ae0916d4ec7bfe3e45c9eff0905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 48/70\n",
      "train_loss: 0.3101, train_acc: 0.8866\n",
      "test_loss: 83.7920, test_acc: 0.8214\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d32832d2d644278ab667506615fe8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60171b360fe54b8da2bc6e56be1e3ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 49/70\n",
      "train_loss: 0.3497, train_acc: 0.8854\n",
      "test_loss: 82.1609, test_acc: 0.8112\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f2ef18a4f6e4140b7a4fac46f126fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55349fca7554042860efa776c684a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 50/70\n",
      "train_loss: 0.3042, train_acc: 0.8904\n",
      "test_loss: 96.0552, test_acc: 0.8367\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47013e478d1a4352864e832e6242e7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad1bf42c1b14cf698b57c3c4590d995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 51/70\n",
      "train_loss: 0.3099, train_acc: 0.8981\n",
      "test_loss: 83.5994, test_acc: 0.7959\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57f36598bd0b4eae902c15428d640b1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4b87606bff4f2ca3964f89160fbc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 52/70\n",
      "train_loss: 0.2528, train_acc: 0.9121\n",
      "test_loss: 87.0611, test_acc: 0.8265\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdcb603d74d439e9579b45d98f6e065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561d709ad1004839ba8938d7f61ccaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 53/70\n",
      "train_loss: 0.2590, train_acc: 0.9236\n",
      "test_loss: 81.5939, test_acc: 0.8571\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60ff3231ceb4ea28a6ae502de3cc880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65af8703367a4a0b88ba35fb18c782fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 54/70\n",
      "train_loss: 0.2602, train_acc: 0.9070\n",
      "test_loss: 91.7022, test_acc: 0.8367\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca59034b4654486b3108fdc22b858a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8821fbb8c8624f58853ac94665acfd90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 55/70\n",
      "train_loss: 0.3249, train_acc: 0.8994\n",
      "test_loss: 74.1789, test_acc: 0.8214\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acc20238a994e4393a5726ac852de61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1eb70cf4ec640ff994199866f08327e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 56/70\n",
      "train_loss: 0.2857, train_acc: 0.9019\n",
      "test_loss: 94.7712, test_acc: 0.8878\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0087d0f97e64bae9ed6ef2d9bca5932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69adfcced94843c2901331ea0ded1c00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 57/70\n",
      "train_loss: 0.2576, train_acc: 0.9146\n",
      "test_loss: 79.3444, test_acc: 0.8776\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949edac98ca841fcb3781a4aeb176a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588d78db81ad47fbb400711b3ac8c52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 58/70\n",
      "train_loss: 0.3053, train_acc: 0.8930\n",
      "test_loss: 82.6000, test_acc: 0.8878\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2266e5387c3409ba2b7ec72b300a63f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe44bbed25449b1a17dfcb9107ec27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 59/70\n",
      "train_loss: 0.2544, train_acc: 0.9185\n",
      "test_loss: 92.5978, test_acc: 0.8980\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bccf9375a20143afbdce064ac656eaad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2accf239a16a467d8b5315597bc4487b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 60/70\n",
      "train_loss: 0.2417, train_acc: 0.9032\n",
      "test_loss: 87.5383, test_acc: 0.8776\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebef0c8d3aec49429ffd8865643cccac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10fe1345f3a40759d7fad363ee36d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 61/70\n",
      "train_loss: 0.2329, train_acc: 0.9210\n",
      "test_loss: 87.9295, test_acc: 0.8673\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78cb89418c104c289bfc8fffccc0364b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405a8b18f1e14f3fa9e1a5f4b93716cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 62/70\n",
      "train_loss: 0.2675, train_acc: 0.9108\n",
      "test_loss: 90.3460, test_acc: 0.8622\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0410b97e66b44f591b754536e641c31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13e54ccbb534128b05350bf3cf67d33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 63/70\n",
      "train_loss: 0.2118, train_acc: 0.9185\n",
      "test_loss: 89.9485, test_acc: 0.8112\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f0575689554dbaa891657c9d78aa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1c368491db41a9ba3283d19d41a6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 64/70\n",
      "train_loss: 0.2000, train_acc: 0.9363\n",
      "test_loss: 80.4762, test_acc: 0.9031\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4db9e2b10f440a7b007cba3ac7b95cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a6d2a9b4814feab370b59c5a243108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 65/70\n",
      "train_loss: 0.2604, train_acc: 0.9108\n",
      "test_loss: 86.8369, test_acc: 0.8214\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd66ddfcbb44242b109f6a3945ca666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5231dcfd36e4ace815d33949c9d0098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 66/70\n",
      "train_loss: 0.2498, train_acc: 0.9223\n",
      "test_loss: 81.4950, test_acc: 0.8929\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7296cef8a0894416a3dfe8ee564e5a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4107677911664aabad16fe5c03ce9198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 67/70\n",
      "train_loss: 0.2694, train_acc: 0.9108\n",
      "test_loss: 97.1074, test_acc: 0.8061\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66c0a37d8c0848759b3e78916acde83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b22b57ed7e4daaa38ff04daa8d4db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 68/70\n",
      "train_loss: 0.2193, train_acc: 0.9274\n",
      "test_loss: 90.6562, test_acc: 0.8520\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac67b4daa104f4f85c853844f06c5a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8d9390fc624f88b0f88cc1a721a112",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 69/70\n",
      "train_loss: 0.2357, train_acc: 0.9083\n",
      "test_loss: 89.9988, test_acc: 0.9082\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba3bae57b3bd4f14b5ec3ab69532df3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([17, 64, 1, 8, 8])\n",
      "input shape: torch.Size([17, 64, 64]),value shape: torch.Size([17, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([17, 64, 64]),transofrmed origin torch.Size([17, 64, 64])\n",
      "after matmul: torch.Size([17, 64, 64])\n",
      "after reshape: torch.Size([17, 64, 1, 8, 8])\n",
      "output shape: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([17, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([17, 1, 64, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "583895daa5404c38a84b6c93037cc85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([32, 64, 1, 8, 8])\n",
      "input shape: torch.Size([32, 64, 64]),value shape: torch.Size([32, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([32, 64, 64]),transofrmed origin torch.Size([32, 64, 64])\n",
      "after matmul: torch.Size([32, 64, 64])\n",
      "after reshape: torch.Size([32, 64, 1, 8, 8])\n",
      "output shape: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([32, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after split: torch.Size([4, 64, 1, 8, 8])\n",
      "input shape: torch.Size([4, 64, 64]),value shape: torch.Size([4, 64, 1, 8, 8])\n",
      "alignment shape after softmax: torch.Size([4, 64, 64]),transofrmed origin torch.Size([4, 64, 64])\n",
      "after matmul: torch.Size([4, 64, 64])\n",
      "after reshape: torch.Size([4, 64, 1, 8, 8])\n",
      "output shape: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after attention: torch.Size([4, 64, 1, 8, 8])\n",
      "shape after reconstruction: torch.Size([4, 1, 64, 64])\n",
      "Epoch: 70/70\n",
      "train_loss: 0.1855, train_acc: 0.9363\n",
      "test_loss: 83.2744, test_acc: 0.9133\n",
      "====================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training the model\n",
    "num_epochs=70\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    train_loss,train_acc=train(attention_cluster,train_data_loader,optimizer,feature_loss,predic_loss)\n",
    "    test_loss,test_acc=test(attention_cluster,test_data_loader,feature_loss,predic_loss)\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}\")\n",
    "    print(f\"train_loss: {train_loss:.4f}, train_acc: {train_acc:.4f}\")\n",
    "    print(f\"test_loss: {test_loss:.4f}, test_acc: {test_acc:.4f}\")\n",
    "    print(\"=\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value shape after split: torch.Size([32, 4, 1, 32, 32])\n",
      "shape after split: torch.Size([32, 4, 1, 8, 8])\n",
      "input shape: torch.Size([32, 4, 64]),value shape: torch.Size([32, 4, 1, 32, 32])\n",
      "alignment shape after softmax: torch.Size([32, 4, 4]),transofrmed origin torch.Size([32, 4, 1024])\n",
      "after matmul: torch.Size([32, 4, 1024])\n",
      "after reshape: torch.Size([32, 4, 1, 32, 32])\n",
      "output shape: torch.Size([32, 4, 1, 32, 32])\n",
      "shape after attention: torch.Size([32, 4, 1, 32, 32])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cfg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m feature,_\u001b[38;5;241m=\u001b[39mattention_cluster(img)\n\u001b[1;32m      7\u001b[0m label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(test_data_loader))[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m----> 8\u001b[0m img_arr\u001b[38;5;241m=\u001b[39mvisualize_gradients(model\u001b[38;5;241m=\u001b[39mattention_cluster,img\u001b[38;5;241m=\u001b[39mimg,label\u001b[38;5;241m=\u001b[39mlabel,cfg\u001b[38;5;241m=\u001b[39m\u001b[43mcfg\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(img_arr\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     11\u001b[0m fig,ax\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m8\u001b[39m,figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m20\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cfg' is not defined"
     ]
    }
   ],
   "source": [
    "# see activation map\n",
    "from models.utils.visualization import visualize_gradients\n",
    "img=next(iter(test_data_loader))[0]\n",
    "img=img.to('cuda')\n",
    "attention_cluster.eval()\n",
    "feature,_=attention_cluster(img)\n",
    "label=next(iter(test_data_loader))[1]\n",
    "img_arr=visualize_gradients(model=attention_cluster,img=img,label=label,cfg=cfg)\n",
    "print(img_arr.shape)\n",
    "\n",
    "fig,ax=plt.subplots(4,8,figsize=(20,20))\n",
    "for i in range(4):\n",
    "    for j in range(8):\n",
    "        ax[i,j].imshow(img_arr[i*4+j].transpose(1,2,0))\n",
    "        ax[i,j].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 16, 1, 16, 16])\n",
      "shape after split: torch.Size([32, 16, 1, 8, 8])\n",
      "input shape: torch.Size([32, 16, 64]),value shape: torch.Size([32, 16, 1, 16, 16])\n",
      "alignment shape after softmax: torch.Size([32, 16, 16]),transofrmed origin torch.Size([32, 16, 256])\n",
      "after matmul: torch.Size([32, 16, 256])\n",
      "after reshape: torch.Size([32, 16, 1, 16, 16])\n",
      "output shape: torch.Size([32, 16, 1, 16, 16])\n",
      "shape after attention: torch.Size([32, 16, 1, 16, 16])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "input: torch.Size([32, 1, 64, 64])\n",
      "input: torch.Size([32, 1, 64, 64])\n",
      "input: torch.Size([32, 1, 64, 64])\n",
      "torch.Size([32, 1, 64, 64])\n",
      "value shape after split: torch.Size([32, 16, 1, 16, 16])\n",
      "shape after split: torch.Size([32, 16, 1, 8, 8])\n",
      "input shape: torch.Size([32, 16, 64]),value shape: torch.Size([32, 16, 1, 16, 16])\n",
      "alignment shape after softmax: torch.Size([32, 16, 16]),transofrmed origin torch.Size([32, 16, 256])\n",
      "after matmul: torch.Size([32, 16, 256])\n",
      "after reshape: torch.Size([32, 16, 1, 16, 16])\n",
      "output shape: torch.Size([32, 16, 1, 16, 16])\n",
      "shape after attention: torch.Size([32, 16, 1, 16, 16])\n",
      "shape after reconstruction: torch.Size([32, 1, 64, 64])\n",
      "input: torch.Size([32, 1, 64, 64])\n",
      "input: torch.Size([32, 1, 64, 64])\n",
      "input: torch.Size([32, 1, 64, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[64, 64]' is invalid for input of size 131072",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m attention_cluster(img)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(feature[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 21\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mattention_cluster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[64, 64]' is invalid for input of size 131072"
     ]
    }
   ],
   "source": [
    "# hook feature map\n",
    "feature=None\n",
    "\n",
    "def hook_fn(module,input,output):\n",
    "    global feature\n",
    "    print(f\"input: {input[0].shape}\")\n",
    "    feature=input\n",
    "    output=output[0]\n",
    "    \n",
    "    feature=input\n",
    "\n",
    "#attention_cluster=AttentionFeatureCluster(32,64,64,6).to('cuda')\n",
    "attention_cluster.after_attention.register_forward_hook(hook_fn)\n",
    "img=next(iter(test_data_loader))[0]\n",
    "img=img.to('cuda')\n",
    "attention_cluster.eval()\n",
    "print(img.shape)\n",
    "attention_cluster(img)\n",
    "print(feature[0].shape)\n",
    "\n",
    "plt.imshow(attention_cluster(img)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[299], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfeature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "feature.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mocked_cfg:\n",
    "    def __init__(self):\n",
    "        self.patch_size=32\n",
    "        self.feature_size=64\n",
    "        self.num_classes=6\n",
    "        self.num_patches=(self.feature_size//self.patch_size)**2\n",
    "        self.blur_size=11\n",
    "        self.model='fcn'\n",
    "        \n",
    "cfg=mocked_cfg()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids-21.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
