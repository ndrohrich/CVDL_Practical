import torch
import torch.nn as nn

import torch
import torch.nn as nn
class AffinityLoss(nn.Module):
    def __init__(self, feature_dim, num_classes):
        """
        Initializes the AffinityLoss module.

        Args:
            feature_dim (int): The dimensionality of the feature vectors.
            num_classes (int): The number of classes in the classification task.
        """
        super(AffinityLoss, self).__init__()
        self.num_classes = num_classes
        self.centers = nn.Parameter(torch.randn(feature_dim, num_classes))


    def forward(self, features, labels):
        """
        Computes the affinity loss.

        Args:
            features (torch.Tensor): Batch of feature vectors of shape (N, D), where N is the batch size and D is the feature dimension.
            labels (torch.Tensor): Ground truth labels of shape (N,).

        Returns:
            torch.Tensor: The computed affinity loss.
        """
        # Get the batch size and feature dimension
        batch_size, feature_dim = features.size()

        # Get the centers corresponding to the ground truth labels
        centers_batch = self.centers[:, labels]

        # Compute intra-class distance (numerator)
        intra_class_dist = torch.sum((features - centers_batch.T) ** 2, dim=1)

        # Compute standard deviation of class centers (denominator)
        center_mean = self.centers.mean(dim=1, keepdim=True)
        inter_class_var = torch.sum((self.centers - center_mean) ** 2) / self.num_classes
        
        # Compute the affinity loss
        loss = torch.sum(intra_class_dist) / (inter_class_var + 1e-6)  # Add epsilon for numerical stability

        return loss